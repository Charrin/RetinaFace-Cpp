7767517
29 29
Input            conv2d_1_input   0 1 conv2d_1_input 0=32 1=32 2=3
Convolution      conv2d_1         1 1 conv2d_1_input conv2d_1 0=16 1=3 11=3 2=1 3=1 4=1 14=1 5=1 6=432
ReLU             activation_1     1 1 conv2d_1 conv2d_1_activation_1
BatchNorm        batch_normalization_1 1 1 conv2d_1_activation_1 batch_normalization_1 0=16
Scale            batch_normalization_1_scale 1 1 batch_normalization_1 batch_normalization_1_batch_normalization_1_scale 0=16 1=1
Convolution      conv2d_2         1 1 batch_normalization_1_batch_normalization_1_scale conv2d_2 0=16 1=3 11=3 2=1 3=1 4=1 14=1 5=1 6=2304
ReLU             activation_2     1 1 conv2d_2 conv2d_2_activation_2
BatchNorm        batch_normalization_2 1 1 conv2d_2_activation_2 batch_normalization_2 0=16
Scale            batch_normalization_2_scale 1 1 batch_normalization_2 batch_normalization_2_batch_normalization_2_scale 0=16 1=1
Pooling          max_pooling2d_1  1 1 batch_normalization_2_batch_normalization_2_scale max_pooling2d_1 0=0 1=2 2=2 3=0 13=0 4=0
Dropout          dropout_1        1 1 max_pooling2d_1 max_pooling2d_1_dropout_1
Convolution      conv2d_3         1 1 max_pooling2d_1_dropout_1 conv2d_3 0=32 1=3 11=3 2=1 3=1 4=1 14=1 5=1 6=4608
ReLU             activation_3     1 1 conv2d_3 conv2d_3_activation_3
BatchNorm        batch_normalization_3 1 1 conv2d_3_activation_3 batch_normalization_3 0=32
Scale            batch_normalization_3_scale 1 1 batch_normalization_3 batch_normalization_3_batch_normalization_3_scale 0=32 1=1
Convolution      conv2d_4         1 1 batch_normalization_3_batch_normalization_3_scale conv2d_4 0=32 1=3 11=3 2=1 3=1 4=1 14=1 5=1 6=9216
ReLU             activation_4     1 1 conv2d_4 conv2d_4_activation_4
BatchNorm        batch_normalization_4 1 1 conv2d_4_activation_4 batch_normalization_4 0=32
Scale            batch_normalization_4_scale 1 1 batch_normalization_4 batch_normalization_4_batch_normalization_4_scale 0=32 1=1
Pooling          max_pooling2d_2  1 1 batch_normalization_4_batch_normalization_4_scale max_pooling2d_2 0=0 1=2 2=2 3=0 13=0 4=0
Dropout          dropout_2        1 1 max_pooling2d_2 max_pooling2d_2_dropout_2
Flatten          flatten_1        1 1 max_pooling2d_2_dropout_2 flatten_1
InnerProduct     dense_1          1 1 flatten_1 dense_1 0=64 1=1 2=131072
ReLU             activation_5     1 1 dense_1 dense_1_activation_5
BatchNorm        batch_normalization_5 1 1 dense_1_activation_5 batch_normalization_5 0=64
Scale            batch_normalization_5_scale 1 1 batch_normalization_5 batch_normalization_5_batch_normalization_5_scale 0=64 1=1
Dropout          dropout_3        1 1 batch_normalization_5_batch_normalization_5_scale batch_normalization_5_dropout_3
InnerProduct     dense_2          1 1 batch_normalization_5_dropout_3 dense_2 0=2 1=1 2=128
Softmax          activation_6     1 1 dense_2 activation_6 0=0
